# HealBridge AI - Post-Discharge Medical Assistant# üè• HealBridge AI: Post-Discharge Medical AI Assistant POC# üè• HealBridge AI: Post-Discharge Medical AI Assistant POC



A simple AI chatbot that helps patients after they leave the hospital. It answers medical questions using a knowledge base and can search the web if needed.



## What It Does> **A sophisticated multi-agent AI system for post-discharge patient care** using RAG, intelligent query optimization, and medical-grade logging.> **A sophisticated multi-agent AI system for post-discharge patient care** using RAG, intelligent query optimization, and medical-grade logging.



- üë§ **Patient Lookup** - Find your discharge information by name

- üí¨ **Chat** - Ask medical questions, get helpful answers

- üìö **Smart Search** - Uses medical knowledge base first, then web if needed[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

- üìã **Keeps History** - Remembers your conversation for context

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)

## Quick Start

[![Status](https://img.shields.io/badge/Status-Production%20Ready%20POC-green.svg)]()[![Status](https://img.shields.io/badge/Status-Production%20Ready%20POC-green.svg)]()

### 1. Install



```bash

git clone https://github.com/yourusername/HealBridge-AI.git------

cd HealBridge-AI



python -m venv venv

source venv/bin/activate  # Windows: venv\Scripts\activate## üìñ Overview## Overview



pip install -r requirements.txt

```

**HealBridge AI** is a Proof of Concept for an intelligent post-discharge care assistant that helps patients manage their recovery with personalized, evidence-based medical guidance. The system implements a sophisticated multi-agent architecture combining RAG, intelligent query optimization, and comprehensive audit logging.**HealBridge AI** is a Proof of Concept (POC) for an intelligent post-discharge care assistant that helps patients manage their recovery with personalized, evidence-based guidance. Built with production-ready architecture using RAG, multi-agent orchestration, and comprehensive logging.

### 2. Setup



Create `.env` file:

```### Key Technologies## Key Features

GROQ_API_KEY=your_api_key_here

DATABASE_URL=postgresql://user:password@localhost/db

```

- üß† **Multi-Agent Architecture** - Specialized agents for patient intake, query optimization, clinical reasoning, and data retrieval- üß† **Multi-Agent Architecture** - Specialized agents for receptionist, query optimization, clinical AI, and database access

### 3. Run

- üìö **Retrieval-Augmented Generation** - Grounds answers in nephrology reference materials with strict confidence gating- üìö **Retrieval-Augmented Generation** - Grounds answers in nephrology reference materials with strict confidence gating

**Web Version (Recommended):**

```bash- üîç **Novel Query Composer Agent** - Rewrites patient questions into retrieval-optimized medical queries (30-40% accuracy improvement)- üîç **Novel Query Composer Agent** - Rewrites patient questions into retrieval-optimized medical queries (30-40% accuracy improvement)

streamlit run frontend/streamlit_app.py

```- üåê **Intelligent Web Fallback** - Seamlessly escalates to web search when KB insufficient- üåê **Intelligent Web Fallback** - Seamlessly falls back to web search when KB is insufficient



**Terminal Version:**- üìã **Medical-Grade Logging** - Complete audit trail for compliance- üìã **Medical-Grade Logging** - Complete audit trail with timestamps for compliance

```bash

python app/main.py- üí¨ **Multi-Turn Chat** - Context-aware conversations with persistent memory- üí¨ **Multi-Turn Chat** - Context-aware conversations with full history

```

- ‚úÖ Patient lookup and personalized greeting

## Project Structure

---- ‚úÖ Multi-turn Q&A with discharge context

```

.- ‚úÖ User-friendly source citations

‚îú‚îÄ‚îÄ agents/                      # AI agents

‚îÇ   ‚îú‚îÄ‚îÄ receptionistAgent.py     # Greets patients## ‚ú® Core Features- ‚úÖ Small-talk detection (gratitude, goodbye, affirmation)

‚îÇ   ‚îú‚îÄ‚îÄ clinicalAiAgent.py       # Answers medical questions

‚îÇ   ‚îú‚îÄ‚îÄ clinicalQueryComposerAgent.py  # Optimizes questions- ‚úÖ Duplicate question prevention

‚îÇ   ‚îî‚îÄ‚îÄ clinicalDbAgent.py       # Gets patient records

‚îú‚îÄ‚îÄ app/| Feature | Benefit |- ‚úÖ Graceful error handling with fallback chains

‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # Terminal chat

‚îú‚îÄ‚îÄ frontend/|---------|---------|

‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py         # Web chat

‚îú‚îÄ‚îÄ rag/| **Query Composer Agent** ‚≠ê | Contextualizes questions ‚Üí 30-40% better retrieval accuracy |## Quick start

‚îÇ   ‚îú‚îÄ‚îÄ ingest.py               # Load medical knowledge

‚îÇ   ‚îî‚îÄ‚îÄ query.py                # Search knowledge| **Strict KB Gating** | Requires 2+ high-confidence hits ‚Üí prevents hallucinations |

‚îú‚îÄ‚îÄ chroma_db/                  # Medical knowledge storage

‚îú‚îÄ‚îÄ logs/                       # Chat logs| **Medical-Grade Logging** | Complete decision traceability ‚Üí compliance-ready |1. Create/activate a Python environment (3.9+ recommended) and install dependencies:

‚îî‚îÄ‚îÄ dummy.json                  # Sample patient data

```| **Graceful Degradation** | KB ‚Üí Web ‚Üí SDK ‚Üí always works |



## How It Works| **Citation Transparency** | User-friendly sources ‚Üí builds trust |```powershell



1. **You enter your name** ‚Üí System finds your discharge info# From the workspace root

2. **You get a greeting** ‚Üí AI welcomes you with your medical details

3. **You ask a question** ‚Üí AI searches medical knowledge base### Capabilitiespip install -r requirements.txt

4. **You get an answer** ‚Üí With sources and citations

5. **You can ask more** ‚Üí It remembers the conversation```



## Technologies Used- ‚úÖ Patient lookup with automatic discharge context loading



- **AI Model:** Groq (llama-3.1)- ‚úÖ Personalized, context-aware greeting2. Ingest the provided PDF (adjust path if needed):

- **Knowledge Storage:** ChromaDB (vector database)

- **Medical Info:** Embeddings from sentences- ‚úÖ Multi-turn Q&A with full chat history

- **Database:** PostgreSQL (patient records)

- **Web Interface:** Streamlit- ‚úÖ Intelligent query rewriting for optimal retrieval```powershell

- **Web Search:** DuckDuckGo (when needed)

- ‚úÖ RAG-based medical answers with clinical citationspython .\rag\ingest.py --pdf .\comprehensive-clinical-nephrology.pdf --persist_dir .\chroma_db --collection default

## Configuration

- ‚úÖ Web search fallback for recent information```

Edit `.env` to change:

- ‚úÖ Small-talk detection (gratitude, goodbye, confirmation)

```env

# Your Groq API key (get free at console.groq.com)- ‚úÖ Duplicate question prevention3. Query the vector DB:

GROQ_API_KEY=your_key

- ‚úÖ User-friendly source citations with collapsible dropdown

# Your database connection

DATABASE_URL=postgresql://user:pass@localhost/db- ‚úÖ Persistent conversation memory```powershell



# How strict to be with answers (0-1)- ‚úÖ Complete audit trailspython .\rag\query.py --query "What are key risk factors?" --persist_dir .\chroma_db --collection default --top_k 5

STRICT_THRESHOLD=0.40

``````



## Database Setup---



Create a table for patients:4. Use the Clinical AI Agent with Groq (RAG + Web fallback)



```sql## üñ•Ô∏è Interfaces

CREATE TABLE patient_discharges (

    id SERIAL PRIMARY KEY,Create a `.env` file in the project root and add your Groq API key:

    patient_name VARCHAR(255),

    discharge_date DATE,- **Streamlit Web UI** (`frontend/streamlit_app.py`) - Modern browser-based interface

    primary_diagnosis VARCHAR(255),

    medications TEXT[],- **CLI Interface** (`app/main.py`) - Interactive terminal chat```env

    dietary_restrictions TEXT,

    warning_signs TEXT,GROQ_API_KEY=your_groq_api_key_here

    discharge_instructions TEXT

);---```

```



## Features

## üöÄ Quick StartAsk a question. The agent will use the local vector DB; if it can‚Äôt find relevant context (based on a distance threshold), it will fall back to web search (DuckDuckGo) and still answer with citations.

‚úÖ Patient lookup by name  

‚úÖ Medical question answering  

‚úÖ Source citations  

‚úÖ Multi-turn conversations  ### Prerequisites```powershell

‚úÖ Small-talk handling (jokes, goodbye)  

‚úÖ Web search fallback  python .\agents\clinicalAiAgent.py --query "Summarize causes of AKI" --persist_dir .\chroma_db --collection default --top_k 5 --threshold 0.45 --llm llama-3.1-8b-instant

‚úÖ Complete conversation logs  

‚úÖ Question optimization for better answers  - Python 3.9+```



## Important: Medical Disclaimer- PostgreSQL (or JSON fallback for POC)



‚ö†Ô∏è **This is NOT a substitute for real medical advice.**- Groq API key ([free tier](https://console.groq.com))Flags:



- Always talk to your doctor- ~2GB disk space- `--threshold` controls when to trust KB context (lower means stricter; cosine distance). If no chunk meets the threshold, the agent uses web search.

- This is for educational purposes only

- Don't use this for emergencies- `--llm` lets you choose a Groq model (e.g., `llama-3.1-8b-instant`, `llama-3.1-70b-versatile`, `mixtral-8x7b-32768`).

- Not a replacement for healthcare professionals

### Installation- `--web_max` controls the number of web results fetched when falling back.

## Contributing



Found a bug? Want to help? Open an issue or create a pull request!

```bash## Notes

## License

# Clone repository

MIT License - see LICENSE file

git clone https://github.com/yourusername/HealBridge-AI.git- The Chroma DB persists in `./chroma_db` (safe to commit to .gitignore).

cd HealBridge-AI- To rebuild the collection from scratch, pass `--reset` to `ingest.py`.

- This setup is LLM-agnostic. You can wire the retrieved chunks into your preferred LLM prompt later (OpenAI/Azure OpenAI/Ollama, etc.).

# Create virtual environment- For Groq usage, set `GROQ_API_KEY` in your environment or in a `.env` file at the project root.

python -m venv venv

source venv/bin/activate  # Windows: venv\Scripts\activate## PostgreSQL Clinical DB Agent



# Install dependenciesSet database credentials as environment variables (or in `.env`):

pip install -r requirements.txt

```env

# Configure environmentPGHOST=localhost

cp .env.example .envPGPORT=5432

# Edit .env with:PGDATABASE=your_db

# GROQ_API_KEY=your_key_herePGUSER=your_user

# DATABASE_URL=postgresql://user:pass@localhost/dbPGPASSWORD=your_password

```PGSSLMODE=prefer

```

### Running the Application

Query by patient name (partial match by default). Replace the table name if yours differs:

```bash

# Web UI (Recommended)```powershell

streamlit run frontend/streamlit_app.pypython .\agents\clinicalDbAgent.py --name "John Smith" --table patient_discharges --limit 3 --json_only

```

# CLI

python app/main.pyOptions:

```- `--match ilike|exact` (default ilike) for partial vs exact name match.

- `--schema` to choose a schema (default public).

### First-Time Setup- `--json_only` prints machine-readable JSON only.



```bash## Receptionist Agent

# Ingest nephrology knowledge base

python rag/ingest.pyInteractive greeting + follow-up using the latest discharge record for the patient, then routes the patient's concern to the Clinical AI Agent with patient context.



# Load sample patients (optional)Requires a Groq API key (set GROQ_API_KEY in your environment or in `.env`).

python scripts/load_dummy_patients.py

```Interactive prompt:



---```powershell

python .\agents\receptionistAgent.py

## üìÅ Project Structure```



```Non-interactive (pass name):

HealBridge-AI/

‚îú‚îÄ‚îÄ agents/                              # Multi-agent system```powershell

‚îÇ   ‚îú‚îÄ‚îÄ receptionistAgent.py            # Greeting & handoff routingpython .\agents\receptionistAgent.py --name "John Smith" --schema public --table patient_discharges --match exact --llm llama-3.1-8b-instant --persist_dir .\chroma_db --collection default --embed_model sentence-transformers/all-MiniLM-L6-v2 --top_k 5 --threshold 0.45 --web_max 5

‚îÇ   ‚îú‚îÄ‚îÄ clinicalQueryComposerAgent.py   # Query optimization (NOVEL)```

‚îÇ   ‚îú‚îÄ‚îÄ clinicalAiAgent.py              # RAG & clinical reasoning

‚îÇ   ‚îî‚îÄ‚îÄ clinicalDbAgent.py              # Patient data retrieval## Clinical Query Composer Agent

‚îÇ

‚îú‚îÄ‚îÄ app/When you want stronger KB retrieval, compose the question using patient context first, then answer:

‚îÇ   ‚îî‚îÄ‚îÄ main.py                         # CLI orchestrator

‚îÇ```powershell

‚îú‚îÄ‚îÄ frontend/python .\agents\clinicalQueryComposerAgent.py --name "John Smith" --question "Is leg swelling related to CKD Stage 3?" --persist_dir .\chroma_db --collection default --embed_model sentence-transformers/all-MiniLM-L6-v2 --top_k 8 --threshold 0.55 --print_composed

‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py                # Web interface```

‚îÇ

‚îú‚îÄ‚îÄ rag/Or provide patient info directly:

‚îÇ   ‚îú‚îÄ‚îÄ ingest.py                       # PDF ingestion & embedding

‚îÇ   ‚îú‚îÄ‚îÄ query.py                        # RAG retrieval```powershell

‚îÇ   ‚îî‚îÄ‚îÄ agent.py                        # RAG pipeline wrapperpython .\agents\clinicalQueryComposerAgent.py --patient_info_json '{"patient_name":"John Smith","primary_diagnosis":"Chronic Kidney Disease Stage 3","medications":["Lisinopril 10mg daily","Furosemide 20mg twice daily"],"dietary_restrictions":"Low sodium, fluid restriction 1.5L/day"}' --question "Why are my legs swollen?" --persist_dir .\chroma_db --collection default --top_k 8 --threshold 0.55 --print_composed

‚îÇ```

‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ logging_setup.py                # Centralized logging
‚îÇ
‚îú‚îÄ‚îÄ chroma_db/                          # Vector database (persistent)
‚îú‚îÄ‚îÄ logs/                               # Application logs
‚îú‚îÄ‚îÄ comprehensive-clinical-nephrology.pdf
‚îú‚îÄ‚îÄ dummy.json                          # Sample patients
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ BRIEF_REPORT.md                     # Technical report
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Configuration

### Environment Variables (.env)

```env
# Groq API
GROQ_API_KEY=your_groq_api_key_here

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/patients_db
DB_SCHEMA=public

# RAG Configuration
PERSIST_DIR=chroma_db
COLLECTION_NAME=default
EMBED_MODEL=sentence-transformers/all-mpnet-base-v2
TOP_K=8
THRESHOLD=0.55
MIN_KB_HITS=2
STRICT_THRESHOLD=0.40

# LLM Configuration
ANSWER_LLM=llama-3.1-8b-instant
COMPOSE_LLM=llama-3.1-8b-instant
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=512

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
```

### Database Schema

```sql
CREATE TABLE public.patient_discharges (
    id SERIAL PRIMARY KEY,
    patient_name VARCHAR(255) NOT NULL,
    discharge_date DATE,
    primary_diagnosis VARCHAR(255),
    medications TEXT[],
    dietary_restrictions TEXT,
    follow_up VARCHAR(500),
    warning_signs TEXT,
    discharge_instructions TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## üí° Usage Examples

### Web UI Workflow

```
1. Enter patient name ‚Üí Lookup record
2. Receive greeting + handoff
3. Ask medical question
4. View answer + collapsible sources
5. Continue multi-turn conversation
```

### CLI Workflow

```bash
$ python app/main.py
> Enter patient name: John Smith
> [Greeting displayed]
> Ask your question: I've been feeling tired
> [Answer with sources]
```

---

## üèóÔ∏è System Architecture

```
Patient Input (Web/CLI)
    ‚Üì
Receptionist Agent
    ‚Üì
Query Composer Agent (NOVEL)
    ‚Üì
Clinical AI Agent
‚îú‚îÄ ChromaDB Retrieval
‚îú‚îÄ Strict Gating
‚îî‚îÄ Web Fallback
    ‚Üì
Response + Citations
    ‚Üì
Audit Logging
```

---

## üîç [NOVEL] Query Composer Agent

**The Competitive Differentiator** ‚≠ê

This agent solves a fundamental RAG limitation: colloquial patient language doesn't match medical knowledge documents.

**Transformation Example:**
```
Raw:       "I'm feeling really tired after waking up"
Optimized: "Post-discharge fatigue and morning tiredness in CKD stage 3; 
            differential including anemia, medication effects, fluid management"
Result:    30-40% better KB match quality
```

---

## üìä Technical Stack

| Layer | Technology |
|-------|-----------|
| **LLM** | Groq llama-3.1-8b-instant |
| **Vector DB** | ChromaDB + all-mpnet-base-v2 |
| **RAG** | LangChain + custom implementation |
| **Web Search** | DuckDuckGo |
| **Database** | PostgreSQL |
| **Frontend** | Streamlit + CLI |
| **Logging** | Python rotating file logger |

---

## üìã Logging & Monitoring

Complete audit trail in `logs/app.log`:

```
session.start / session.end
patient.lookup (success/failure)
receptionist.greeting / receptionist.handoff
composer.query (transformation)
retrieval.decision (KB vs Web)
answer.generated (sources, scores)
sources.list (citations)
smalltalk.* (classification)
```

View logs:
```bash
tail -f logs/app.log
```

---

## ‚öñÔ∏è Medical Disclaimer

‚ö†Ô∏è **IMPORTANT: Educational Use Only**

This AI assistant is a **Proof of Concept** for educational purposes only. It is **NOT** a substitute for professional medical advice.

**Always consult qualified healthcare professionals before making medical decisions.**

This system:
- Provides general information based on guidelines
- Uses AI-generated responses (may contain errors)
- Is **NOT** for emergency situations
- Should **NOT** delay professional consultation

**For urgent medical concerns, contact healthcare providers immediately.**

---

## ü§ù Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -m 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open a Pull Request

---



